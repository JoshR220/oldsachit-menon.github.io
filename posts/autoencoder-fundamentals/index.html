<!DOCTYPE html>
<html prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article#
" lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Autoencoder Fundamentals | Sachit Menon</title>
<link href="../../assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<link href="../../assets/css/ipython.min.css" rel="stylesheet" type="text/css">
<link href="../../assets/css/nikola_ipython.css" rel="stylesheet" type="text/css">
<meta name="theme-color" content="#5670d4">
<meta name="generator" content="Nikola (getnikola.com)">
<link rel="alternate" type="application/rss+xml" title="RSS" href="../../rss.xml">
<link rel="canonical" href="https://sachit-menon.github.io/posts/autoencoder-fundamentals/">
<script type="text/x-mathjax-config">
 MathJax.Hub.Config({
     tex2jax: {
         inlineMath: [ ['$','$'], ["\\(","\\)"] ],
         displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
         processEscapes: true
     },
     displayAlign: 'center', // Change this to 'left' if you want left-aligned equations.
     "HTML-CSS": {
         styles: {'.MathJax_Display': {"margin": 0}}
     }
 });
 </script><!--[if lt IE 9]><script src="../../assets/js/html5.js"></script><![endif]--><meta name="author" content="Sachit Menon">
<link rel="prev" href="../independent-component-analysis/" title="Independent Component Analysis" type="text/html">
<meta property="og:site_name" content="Sachit Menon">
<meta property="og:title" content="Autoencoder Fundamentals">
<meta property="og:url" content="https://sachit-menon.github.io/posts/autoencoder-fundamentals/">
<meta property="og:description" content="An Introduction to Autoencoders¶






This is one writeup in what I'm hoping to make a series of posts on representation learning and unsupervised methods in general. I've noticed that there are far ">
<meta property="og:type" content="article">
<meta property="article:published_time" content="2018-11-04T18:31:43-05:00">
</head>
<body>
<a href="#content" class="sr-only sr-only-focusable">Skip to main content</a>

<!-- Menubar -->

<nav class="navbar navbar-expand-md static-top mb-4
navbar-dark bg-dark
"><div class="container">
<!-- This keeps the margins nice -->
        <a class="navbar-brand" href="https://sachit-menon.github.io/">

            <span id="blog-title">Sachit Menon</span>
        </a>
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#bs-navbar" aria-controls="bs-navbar" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
        </button>

        <div class="collapse navbar-collapse" id="bs-navbar">
            <ul class="navbar-nav mr-auto">
<li class="nav-item">
<a href="../" class="nav-link">Posts</a>
                </li>
<li class="nav-item">
<a href="../../categories/" class="nav-link">Tags</a>
                </li>
<li class="nav-item">
<a href="../../rss.xml" class="nav-link">RSS feed</a>

                
            </li>
</ul>
<ul class="navbar-nav navbar-right">
<li class="nav-item">
    <a href="index.ipynb" id="sourcelink" class="nav-link">Source</a>
    </li>


                
            </ul>
</div>
<!-- /.navbar-collapse -->
    </div>
<!-- /.container -->
</nav><!-- End of Menubar --><div class="container" id="content" role="main">
    <div class="body-content">
        <!--Body content-->
        
        
<article class="post-text h-entry hentry postpage" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title" itemprop="headline name"><a href="." class="u-url">Autoencoder Fundamentals</a></h1>

        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                    Sachit Menon
            </span></p>
            <p class="dateline">
            <a href="." rel="bookmark">
            <time class="published dt-published" datetime="2018-11-04T18:31:43-05:00" itemprop="datePublished" title="2018-11-04 18:31">2018-11-04 18:31</time></a>
            </p>
            
        <p class="sourceline"><a href="index.ipynb" class="sourcelink">Source</a></p>

        </div>
        

    </header><div class="e-content entry-content" itemprop="articleBody text">
    <div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="An-Introduction-to-Autoencoders">An Introduction to Autoencoders<a class="anchor-link" href="#An-Introduction-to-Autoencoders">¶</a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><em>This is one writeup in what I'm hoping to make a series of posts on representation learning and unsupervised methods in general. I've noticed that there are far fewer resources out there detailing these topics than there are for common supervised learning topics, and next-to-none that show them off in practice (i.e. with code) along with the underlying math. I'd like these posts to be accessible to a wider audience while still providing mathematical intuition.</em></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Part-1:-Motivation-and-Introduction">Part 1: Motivation and Introduction<a class="anchor-link" href="#Part-1:-Motivation-and-Introduction">¶</a>
</h3>
<p><em>What is an autoencoder and why should I care?</em></p>
<p>The core concept underlying all autoencoders is deceptively simple. Let's break it down from the name instead of memorizing it as just another term. The word 'autoencoder' is made up of 'auto,' meaning self, and 'encoder,' meaning something that transforms information in one form (or code) to another. An autoencoder is a neural network that takes in data, transforms it, and tries to output the same data that it was given.</p>
<p>Cool. We now know what an autoencoder is. Article over, right? Well, not quite.</p>
<p>Our definition as it currently stands makes sense, but seems rather... useless. Why go through the trouble of training a neural network to get an imperfect approximation of the identity function when we could just return our input data? The answer is that we don't really care about the output of our network itself; in fact, when using autoencoders, we never even expect it to perfectly output the data we gave it as input. What's of importance to us is the <em>transformation</em> step. All autoencoders 
possess some transformed intermediate state of the data between the input and output, called the <strong>code</strong>. The part of the autoencoder that outputs the code is unsurprisingly referred to as the <strong>encoder</strong>, while the remainder (which tries to reconstruct the input from the code) is perhaps even more unsurprisingly dubbed the <strong>decoder</strong>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="diagrams/undercomplete_ae.png" alt="title"><strong>An illustration of an autoencoder.</strong> Our input data $\boldsymbol x$ is fed into the encoder function $f$ to create the code; the code is in turn fed into the decoder $\boldsymbol g$ to obtain the output, which we will compare to our input. (In particular, this is visually closest to an <em>undercomplete</em> autoencoder, described in the next section.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>As things currently stand, however, this 'code' doesn't seem particularly useful either. One can easily imagine a neural network with enough capacity being perfectly happy to create some arbitrary approximately invertible function as the encoder and its inverse as the decoder, changing both in tandem to get the identity function as their composite. But the key to (useful) autoencoders is that we aren't going to let our network learn the identity function alone; we're instead going to bully it into learning a code with properties we'd like to have in a(n approximately invertible) transformation of our data at the expense of being able to perfectly reconstruct the input.</p>
<p>Thus, autoencoders are an extremely powerful framework for <em>representation learning</em>. Once we come up with properties we'd like to have in a representation of our data, we can try and constrain our network to learn a code with those properties.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Part-2:--Undercomplete-Autoencoders">Part 2:  Undercomplete Autoencoders<a class="anchor-link" href="#Part-2:--Undercomplete-Autoencoders">¶</a>
</h3>
<p>Now that we have this framework in mind, let's think of properties we might like a representation to have. Oftentimes, the data we are working with is high-dimensional in nature. In order to avoid the curse of dimensionality or to extract semantically meaningful features, we might want some low-dimensional representation of our high-dimensional data -- hence the existence of a whole host of dimensionality reduction techniques in the literature, most well-known being by way of principal components analysis (PCA). (This was actually the original motivation behind the autoencoder, and can be considered the most 'vanilla' flavor of them.)</p>
<p>Thus, we bottleneck the number of dimensions in our network at the code to be lower than the number of dimensions in the input data. We then structure our decoder as a function from the lower number of dimensions to the original number to bring it back up.</p>
<p>Let's see what that looks like in code instead of words! For our first autoencoder, we'll use simple linear transformations for encoding and decoding so we can reason about what's going on intuitively, but keep in mind the main power behind autoencoders comes from their use of neural networks (i.e. incredibly versatile function approximators) for both steps.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [1]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># imports</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="o">%</span><span class="k">matplotlib</span> inline
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">style</span><span class="o">=</span><span class="s1">'whitegrid'</span><span class="p">)</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="k">import</span> <span class="n">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="k">import</span> <span class="n">datasets</span><span class="p">,</span> <span class="n">transforms</span>

<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">);</span> <span class="c1"># set seed for consistent results</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We first must define how many dimensions we want the code to be. This is highly dependent on the number of dimensions in the input -- there is no magic number you can always pick that will give you the results you want! (It also depends on what you plan on using the code for; but these are considerations for downstream tasks.)</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [2]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">input_dimensions</span> <span class="o">=</span> <span class="mi">784</span>
<span class="n">code_dimensions</span> <span class="o">=</span> <span class="mi">32</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We're going to define classes for the encoder and decoder networks. This might seem redundant with our small network now, but is good practice for making encoders and decoders with more complicated architectures than a single linear layer.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [3]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">Encoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    Encoder class for linear autoencoder. Takes in data of dimension `input_dimensions`, </span>
<span class="sd">    conducts a linear transformation, and outputs the resulting code of dimension `code_dimensions`.</span>
<span class="sd">    """</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_dimensions</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">code_dimensions</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Encoder</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_dimensions</span><span class="p">,</span> <span class="n">code_dimensions</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [4]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">Decoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    Decoder class for linear autoencoder. Takes in data of dimension `code_dimensions`, </span>
<span class="sd">    conducts a linear transformation, and outputs the resulting output of dimension `input_dimensions`.</span>
<span class="sd">    """</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">code_dimensions</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">input_dimensions</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Decoder</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">code_dimensions</span><span class="p">,</span> <span class="n">input_dimensions</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Our full autoencoder is then the encoder followed by the decoder.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [5]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">LinearAutoencoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    Class for linear autoencoder. Composite of Encoder and Decoder classes above.</span>
<span class="sd">    """</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_dimensions</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">code_dimensions</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">LinearAutoencoder</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encode</span> <span class="o">=</span> <span class="n">Encoder</span><span class="p">(</span><span class="n">input_dimensions</span><span class="p">,</span> <span class="n">code_dimensions</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decode</span> <span class="o">=</span> <span class="n">Decoder</span><span class="p">(</span><span class="n">code_dimensions</span><span class="p">,</span> <span class="n">input_dimensions</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="c1"># from input_dimensions-&gt;code_dimensions...</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="c1"># and back from code_dimensions-&gt;input_dimensions</span>
        <span class="k">return</span> <span class="n">x</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now we have some general setup to do before we can get training, but this is somewhat usecase-specific and not that important to understanding autoencoders conceptually.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [6]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">'cuda'</span><span class="p">)</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">'cpu'</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [7]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># some hyperparameters</span>
<span class="n">batch_sz</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">test_batch_sz</span> <span class="o">=</span> <span class="mi">100</span>

<span class="n">learning_rate</span> <span class="o">=</span> <span class="mi">10</span><span class="o">**</span><span class="p">(</span><span class="o">-</span><span class="mf">1.5</span><span class="p">)</span>
<span class="n">momentum</span> <span class="o">=</span> <span class="mf">0.5</span>

<span class="n">n_epochs</span> <span class="o">=</span> <span class="mi">20</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [8]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># set dataloader kwargs</span>
<span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s1">'num_workers'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">'pin_memory'</span><span class="p">:</span><span class="kc">True</span><span class="p">}</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="p">{}</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [9]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># preprocessing</span>
<span class="n">img_transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">((</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span> <span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">))</span>
<span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [10]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># create dataloaders to serve up MNIST images as example data -- see MNIST example in the official documentation </span>
<span class="n">train_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="s1">'../data'</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span> <span class="n">img_transform</span><span class="p">),</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_sz</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [11]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">test_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="s1">'../data'</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">img_transform</span><span class="p">),</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="n">test_batch_sz</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We'll set up our model and use stochastic gradient descent with momentum as our optimizer (simplicity is always best when complexity isn't necessary!).</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [12]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">LinearAutoencoder</span><span class="p">(</span><span class="n">input_dimensions</span><span class="p">,</span> <span class="n">code_dimensions</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="n">momentum</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [13]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Optimizer</span><span class="p">,</span> <span class="n">device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> 
          <span class="n">train_loader</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">dataloader</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">,</span> <span class="n">epoch</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    Executes one epoch of training given a model, optimizer, device, dataloader, and epoch number.</span>
<span class="sd">    """</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_loader</span><span class="p">):</span>
        <span class="n">inp</span> <span class="o">=</span> <span class="n">inp</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">input_dimensions</span><span class="p">)</span>
        <span class="n">inp</span> <span class="o">=</span> <span class="n">inp</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> 
        <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inp</span><span class="p">)</span> <span class="c1"># here we put the input image through the autoencoder</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">mse_loss</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">inp</span><span class="p">)</span> <span class="c1"># then compare output to input via mean-square-error</span>
        
        <span class="c1"># good to check that our values are still sane and nothing has gone horribly wrong</span>
        <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">()</span> <span class="ow">or</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span> <span class="ow">or</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">==</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">'Gradient vanished/exploded'</span><span class="p">)</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s1">'Died'</span><span class="p">)</span>
            <span class="k">break</span>
        
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span> <span class="c1"># compute gradients</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span> <span class="c1"># conduct step of gradient descent</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span> <span class="c1"># zero out gradients to avoid messing with future iterations</span>
        
        <span class="k">if</span> <span class="n">batch_idx</span> <span class="o">%</span> <span class="mi">1000</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">'Train Epoch: </span><span class="si">{}</span><span class="s1"> [</span><span class="si">{}</span><span class="s1">/</span><span class="si">{}</span><span class="s1"> (</span><span class="si">{:.0f}</span><span class="s1">%)]</span><span class="se">\t</span><span class="s1">Loss: </span><span class="si">{:.6f}</span><span class="s1">'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                <span class="n">epoch</span><span class="p">,</span> <span class="n">batch_idx</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">inp</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">),</span>
                <span class="mf">100.</span> <span class="o">*</span> <span class="n">batch_idx</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">),</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()))</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [14]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">test</span><span class="p">(</span><span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">test_loader</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">dataloader</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">,</span> <span class="n">epoch</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    Computes error on test set given a model, device, dataloader, and epoch number.</span>
<span class="sd">    """</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">test_loss</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">test_loader</span><span class="p">):</span>
            <span class="n">inp</span> <span class="o">=</span> <span class="n">inp</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">input_dimensions</span><span class="p">)</span>
            <span class="n">inp</span> <span class="o">=</span> <span class="n">inp</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inp</span><span class="p">)</span>
            <span class="n">test_loss</span> <span class="o">+=</span> <span class="n">F</span><span class="o">.</span><span class="n">mse_loss</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">inp</span><span class="p">)</span>
    
    <span class="n">test_loss</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">Test set: Average loss: </span><span class="si">{:.4f}</span><span class="se">\n</span><span class="s1">'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">test_loss</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>All that's left is to train our model and see the results!</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [15]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_epochs</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">train</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">epoch</span><span class="p">)</span>
    <span class="n">test</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">test_loader</span><span class="p">,</span> <span class="n">epoch</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Train Epoch: 1 [0/60000 (0%)]	Loss: 1.000938
Train Epoch: 1 [32000/60000 (53%)]	Loss: 0.257497

Test set: Average loss: 0.0025

Train Epoch: 2 [0/60000 (0%)]	Loss: 0.244470
Train Epoch: 2 [32000/60000 (53%)]	Loss: 0.238129

Test set: Average loss: 0.0024

Train Epoch: 3 [0/60000 (0%)]	Loss: 0.222586
Train Epoch: 3 [32000/60000 (53%)]	Loss: 0.237073

Test set: Average loss: 0.0021

Train Epoch: 4 [0/60000 (0%)]	Loss: 0.208160
Train Epoch: 4 [32000/60000 (53%)]	Loss: 0.203348

Test set: Average loss: 0.0019

Train Epoch: 5 [0/60000 (0%)]	Loss: 0.197845
Train Epoch: 5 [32000/60000 (53%)]	Loss: 0.175188

Test set: Average loss: 0.0017

Train Epoch: 6 [0/60000 (0%)]	Loss: 0.181806
Train Epoch: 6 [32000/60000 (53%)]	Loss: 0.155630

Test set: Average loss: 0.0016

Train Epoch: 7 [0/60000 (0%)]	Loss: 0.153001
Train Epoch: 7 [32000/60000 (53%)]	Loss: 0.155533

Test set: Average loss: 0.0015

Train Epoch: 8 [0/60000 (0%)]	Loss: 0.154720
Train Epoch: 8 [32000/60000 (53%)]	Loss: 0.156239

Test set: Average loss: 0.0014

Train Epoch: 9 [0/60000 (0%)]	Loss: 0.143948
Train Epoch: 9 [32000/60000 (53%)]	Loss: 0.147039

Test set: Average loss: 0.0014

Train Epoch: 10 [0/60000 (0%)]	Loss: 0.139918
Train Epoch: 10 [32000/60000 (53%)]	Loss: 0.135999

Test set: Average loss: 0.0013

Train Epoch: 11 [0/60000 (0%)]	Loss: 0.141453
Train Epoch: 11 [32000/60000 (53%)]	Loss: 0.126618

Test set: Average loss: 0.0013

Train Epoch: 12 [0/60000 (0%)]	Loss: 0.126350
Train Epoch: 12 [32000/60000 (53%)]	Loss: 0.123183

Test set: Average loss: 0.0012

Train Epoch: 13 [0/60000 (0%)]	Loss: 0.118564
Train Epoch: 13 [32000/60000 (53%)]	Loss: 0.123543

Test set: Average loss: 0.0012

Train Epoch: 14 [0/60000 (0%)]	Loss: 0.122253
Train Epoch: 14 [32000/60000 (53%)]	Loss: 0.125982

Test set: Average loss: 0.0012

Train Epoch: 15 [0/60000 (0%)]	Loss: 0.118890
Train Epoch: 15 [32000/60000 (53%)]	Loss: 0.116815

Test set: Average loss: 0.0011

Train Epoch: 16 [0/60000 (0%)]	Loss: 0.119878
Train Epoch: 16 [32000/60000 (53%)]	Loss: 0.110570

Test set: Average loss: 0.0011

Train Epoch: 17 [0/60000 (0%)]	Loss: 0.111909
Train Epoch: 17 [32000/60000 (53%)]	Loss: 0.108714

Test set: Average loss: 0.0011

Train Epoch: 18 [0/60000 (0%)]	Loss: 0.112195
Train Epoch: 18 [32000/60000 (53%)]	Loss: 0.105414

Test set: Average loss: 0.0011

Train Epoch: 19 [0/60000 (0%)]	Loss: 0.116659
Train Epoch: 19 [32000/60000 (53%)]	Loss: 0.110422

Test set: Average loss: 0.0010

Train Epoch: 20 [0/60000 (0%)]	Loss: 0.109862
Train Epoch: 20 [32000/60000 (53%)]	Loss: 0.086314

Test set: Average loss: 0.0010

</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We ended up with a test MSE of 0.001. Is this good? Well, as far as the quality of the reconstruction goes, it seems pretty decent in some handwavey sense considering our values range from 0 to 1. But humans are visual creatures: best way to see how it's doing is to actually see it!</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [16]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># function to un-normalize the output of the network to make it look like the original images</span>
<span class="k">def</span> <span class="nf">to_img</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [17]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># get an example batch and push it through the network</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">x</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">test_loader</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">input_dimensions</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">to_img</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>plt.imshow((model.encode.fc1.weight.t() @ model.decode.fc1.weight.t()).detach().cpu().numpy().T, cmap='Greys_r')plt.imshow(model.encode.fc1.weight.detach().cpu().numpy() @ model.decode.fc1.weight.detach().cpu().numpy(), cmap='Greys_r')
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Displaying our example and its corresponding output,</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [18]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">'Greys_r'</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[18]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&lt;matplotlib.image.AxesImage at 0x7fcf51695da0&gt;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,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">
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [19]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">y</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">'Greys_r'</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[19]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&lt;matplotlib.image.AxesImage at 0x7fcf517486a0&gt;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,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">
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>with the (uninterpretable) 32-dimensional code as</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [20]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">x</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[20]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>array([ 1.2461367 ,  0.7578721 , -0.80333775,  0.17708406,  2.0784078 ,
       -1.2867155 ,  0.459029  , -2.3941464 ,  0.10984115,  0.59566885,
       -1.8090788 , -2.0377617 , -2.190893  ,  0.2924345 , -0.20564324,
        0.10396053, -3.552227  , -1.2485214 , -0.8760196 , -1.0671576 ,
       -3.8653336 , -0.44916114,  1.0365984 ,  1.1902565 , -0.1348641 ,
        0.2300794 ,  0.6650476 , -1.5262647 ,  3.0209737 ,  0.59753466,
        0.12191479, -3.11799   ], dtype=float32)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can see that the output still is very clearly a 1, but is not quite the same as what we put in. This should make sense to us as we did essentially did some lossy compression by a factor of 24.5x -- definitely non-negligible! The autoencoder learned what combinations of the input dimensions it could make in 32 dimensions to best squeeze as much information in as possible to be able to reconstruct the input.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Part-3:-Conclusion">Part 3: Conclusion<a class="anchor-link" href="#Part-3:-Conclusion">¶</a>
</h3>
<p>In this post, we took a look at the inner workings of the simplest variety of autoencoder, the undercomplete autoencoder; that is, a neural network that maps its input to itself with an intermediate layer of fewer dimensions. But this is just the beginning! More importantly, we introduced the autoencoder as a framework for representation learning given how we apply constraints. In the future, we'll see how this can be used for things other than dimension reduction.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Postscript">Postscript<a class="anchor-link" href="#Postscript">¶</a>
</h4>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>P.S. In this case, we only allowed its combinations to be linear by construction of our encoder and decoder. As a fun note, this should feel very familiar to the linear algebra types out there: what we have is a special case of autoencoder construction that's equivalent to principal components analysis (PCA). Given our data is mean-centered here, this just means our network is learning to project into the subspace of the eigenspace spanned by the first $32$ eigenvectors (ordered by 'importance'/magnitude of eigenvalue). An brief, handwavey outline of why this is the case: PCA can be thought of as trying finding the subspace we can project into that minimizes reconstruction error of how far our projections are from the original points; this is what a linear autoencoder is also doing.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [ ]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
</div>
    </div>
    <aside class="postpromonav"><nav><ul class="pager hidden-print">
<li class="previous">
                <a href="../independent-component-analysis/" rel="prev" title="Independent Component Analysis">Previous post</a>
            </li>
        </ul></nav></aside><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML" integrity="sha256-SDRP1VVYu+tgAGKhddBSl5+ezofHKZeI+OzxakbIe/Y=" crossorigin="anonymous"></script><script type="text/x-mathjax-config">
 MathJax.Hub.Config({
     tex2jax: {
         inlineMath: [ ['$','$'], ["\\(","\\)"] ],
         displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
         processEscapes: true
     },
     displayAlign: 'center', // Change this to 'left' if you want left-aligned equations.
     "HTML-CSS": {
         styles: {'.MathJax_Display': {"margin": 0}}
     }
 });
 </script></article><!--End of body content--><footer id="footer">
            Contents © 2018         <a href="mailto:sachit.menon@duke.edu">Sachit Menon</a> - Powered by         <a href="https://getnikola.com" rel="nofollow">Nikola</a>         
            
        </footer>
</div>
</div>


        <script src="../../assets/js/all-nocdn.js"></script><!-- fancy dates --><script>
    moment.locale("en");
    fancydates(0, "YYYY-MM-DD HH:mm");
    </script><!-- end fancy dates --><script>
    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element) {
            return element.getElementsByTagName('img')[0].alt;
    }});
    </script>
</body>
</html>
